%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************

\chapter{Introduction}  %Title of the First Chapter

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi

%********************************** %First Section  **************************************
% The introduction has to explain
% 1. what was done
% 2. the reason why and the context of the work
% 3. what goals it is meant to achieve
% 4. how it improves on previous work. What does the previous method not do?

An important part of live cell microbiology is the accurate measurement and tracking of cell morphology during an experiment. Using a microscope, there are many different ways of observing the cells ranging from brightfield microscopy to 3D fluorescence reconstructions. Both 2D and 3D shape data from the cells along with their speed and directionality can provide information on the effectiveness of drugs or other agents in the experiment. The processing of cell data often relies on the quality of Cell Segmentation, or the automatic or manual differentiation of Objects of Interest, such as cells, from the background. Many algorithms and software packages, such as Cellprofiler and ImageJ, are used to segment cells automatically, yielding variable quality.

A key limitation in widely used software that this paper seeks to address is the inability to account for consistent features that cannot be easily located in 3D data. 3D image data, such as from a confocal microscope, contains information about an environment on many focal planes [ref]. Objects can appear blurred or in focus depending the current focal plane. Consequently, features that are useful for segmentation; dark edges, uniform bright interiors, and other features such as fluorescent markers placed within cells are subject to any fluctuations in focus or the movement of objects vertically in the environment. This prevents consistent segmentation of the cell.

The environment used in this study is a microfludics chip built to simulate a human blood vessel. This type of chip, a microchannel framework printed on a PDMS substrate, is widely used in the medical industry to mimic body tissue [ref]. The 3D nature of this setup requires the use of confocal microscopy or similar methods to observe objects in all parts of the environment. In this case, a confocal microscope was used to record data in both a brightfield channel and a fluorescent GFP channel. A number of limitations on the image quality, discussed in Chapter [ref], prevent more powerful direct 3D methods to be used for segmentation. This necessitates a deeper investigation into how the currently available brightfield and GFP information can be used to segment the cells consistently.

The problem of consistently recognizing objects in a 3D environment using the brightfield is partially addressed in the 2009 study by Selinummi et al. [ref] They attempted to remove the problem of finding objects in 3D by studying the variance of vertical brightness profiles in the brightfield. This had the effect of simplifying 3D data into a 2D plane containing relevant object shapes, from which segmentation could be done more easily. Although this was effective in their case, this has several disadvantages that the current work aims to solve. Notably, it performs poorly in a multicellular environment, necessary for this and many other studies. This is discussed in more detail in Chapter [ref].

The current work builds on the idea of studying vertical intensity profiles by applying this concept instead to the GFP. In the current data, the low quality GFP does not show the outlines of cells accurately. This is due to the internal cellular distribution of the GFP, described in Chapter [ref]. The central regions of the cell (not including the nucleus) are highlighted, so it can be used to locate the general bulk of the cell. The brightfield, on the other hand, shows the edges of the cell more clearly, but only if the cell is in focus (at the correct level). Edges of the cell start to fade along protrusions. In this study, in order to be useful, any segmentation done must include accurate outlines of long cell protrusions to determine cell motility and behaviour.

The method described here uses the bulk of the cell visible in the GFP to locate the level in the data needed to ensure consistently clear dark edges in the brightfield, yielding accurate cell shape. The GFP and brightfield data represent the same physical space. This correspondence is exploited to allow information about the GFP channel to aid searching for features in the brightfield. The correct edges are located by building a vertical GFP intensity distribution for each pixel and selecting pixels from the brightfield data that match the level of the distribution peak. Several other properties of this GFP ``profile'' can be used to find different information about the cells. This is described in more detail in Chapter [ref].
