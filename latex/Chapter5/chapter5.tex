%*******************************************************************************
%****************************** Fifth Chapter *********************************
%*******************************************************************************

\chapter{Results and discussion}

\ifpdf
    \graphicspath{{Chapter5/Figs/Raster/}{Chapter5/Figs/PDF/}{Chapter5/Figs/}}
\else
    \graphicspath{{Chapter5/Figs/Vector/}{Chapter5/Figs/}}
\fi

%********************************** %First Section  **************************************
\section{Introduction}

To say that this method is an improvement on previously available methods is an understatement. This must be shown using comparable data. The best way to provide this data is to attempt to segment images from the current experiment. The methods can be compared easily under similar conditions using the same dataset. A readily available property of the cell instances found is the projected cell area. Other properties are the number and orientation of the cell protrusions. These will also be compared to judge the difference between the methods.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{501_zbf_comparison}
 \caption{
 	zBF comparison
 }
 \label{fig:zbfcomparison}
\end{figure}

Despite the improvements made, the method developed is not without error. There are parameters that have optimal ranges, but outside those ranges, the method can fail. Some physical properties of the environment can limit the effectiveness of the method, for example, if the level of the GFP is too low to generate an accurate estimate of the Z level, the focus of GFP marked objects will not be corrected accurately, and the results will not be useful. Additionally, some configurations of cells in close proximity can cause problems for this method. A clear example is when two cell lie vertically one on top of the other, causing two visible peaks in the GFP. This, and other examples are discussed in the last section [ref].

An important point when comparing different methods is the fact that there is no ``ground truth", or definitely correct answer to the question of the projected area of a cell, and despite the attempts of Selinummi et al. to define theirs as the segmentation of the projected GFP image [ref], all images are subject to error as are the results of their segmentation, and the results are judged subjectively. The only viable automatic means of judging different methods is to compare their consistency and repeatability. They could, however, be consistenty and repeatably wrong. For this reason, the ground truth chosen for the comparison of the methods shown here is the manual segmentation, or outlines of the cells drawn by eye on the zBF image. Only of sample of the frames are considered since manual segmentation is very time consuming.

Yet another problem, is that not even the manual segmentation can be considered the ground truth. The human eye cannot be trusted to determine the shape of an object which it is totally unfit to identify in an environment that does not lend itself to casual observation. Despite this obstructing piece of philosophy, the final judgement must lie with something, and the best thing available is human vision, which is not saying much in the microscopic world. We are left with no choice but to accept a system of pattern recognition whose highest reccommendation is that it insists on discovering human faces wherever it looks [ref].

\section{zBF parameters: R, Delta Z, Sigma}

The three parameters that contribute to the generation of zBF must be carefully chosen, since a low quality result will be useless for segmentation. An analysis of the sensativity of the result to changes in the parameters can be used to determine the optimum values. Below, some examples of parameters chosen outside the optimal ranges are shown and some consequences of their segmentation is investigated.

\subsection{The radius of GFP linear smoothing: $R$}

The parameter $R$ is the radius of the linear smoothing filter applied to the GFP in order to generate a profile for a point in XY. The filter mixes values in XY, but not Z. It has the effect of reducing noise and making transitions between levels of neighbouring pixels more fluid. This helps to reduce the problem of cross-level artifacts, discussed in Section [ref]. In the case where neighbouring objects in XY has very different levels in Z, the level transition would be smoothed such that the point half way between them would be assigned to a level half way in Z. While this case has not been observed, it could lead to strange results, such as half of each cell being in focus, while the halves closest to the other cell are out of focus. This would depend on the radius of the linear filter, but at a certain point, the information is too smoothed and ceases to be useful. Below [ref] is an example of the linear filter set too high. The logical limit is a smoothing filter the size of the image itself in XY. This would simply yield the sum or mean of the GFP for each focal plane, which would not provide any more information than where most of the cells were found in the environment.

On the other hand, if the size of the linear filter is too low, such as a single pixel, the noise in the GFP would dominate the Z estimate, leading to highly fluctuating Z values across even a single cell. The result in the zBF image is an extremely noisy cell interior and edge, surrounded by an equally noisy background. This does not lend itself to accurate segmentation. Below [ref] is an example of the linear filter using a small $R$.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{502_r_variation}
 \caption{
 	Varying R
 }
 \label{fig:rvariation}
\end{figure}

\subsection{The brightfield level correction: $\Delta Z$}

The weakest part of the method is the spatial relationship between the brightfield and the GFP and the decision about the value of [Delta Z]. The brightfield is subject to fluctuations from the autofocus and has no intrinsic spatial information. The most important piece of information relating the GFP and the brightfield is for a hypothetical fixed object in focus in the brightfield, the GFP representation will always correspond to that level of focus. This is because the position of the microscope hardware is constant for a single frame and is set by the autofocus estimate from the brightfield. Assuming the same physical space is represented in both, the GFP can be used to account for the autofocus fluctuations, but the relationship between the GFP representation and the appearance of an object in the brightfield is arbitrary. A cell may be ``in focus" as far as possible, but still not be clearly visible by a human. This hinders manual tracking. optimum features for observation may not correspond to optimum features for segmentation. For tracking, it most effective to observe an object in a solid colour with or without clear edges since the precise shape is not necessary to indicate object centres. For segmentation, a clear object boundary with dark edges and a smooth, uniformally coloured interior yields the most accurate shape. This discrepancy is represented by the empirically determined value, delta-Z. Through further study, a value could be found automatically, but the focus level for optimum human observation is highly subjective.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{503_deltaz_variation}
 \caption{
 	Delta Z variation
 }
 \label{fig:deltazvariation}
\end{figure}



\subsection{The radius of level gaussian blur: $\Sigma$}

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{504_sigma_variation}
 \caption{
 	GFP profile
 }
 \label{fig:sigmavariation}
\end{figure}

\subsection{Final choice of parameters}

The three variables used to produce zBF were fixed to the following values:

[TABLE OF VALUES WITH REASONS FOR THOSE CHOICES]

\subsection{The subject of the background}

It should be noted that background pixels in XY that contain very little GFP at any Z, and thus have very flat profiles, are still assigned a value for the Z position. This may appear misleading, as it can be highly random as the ``maximum" of a flat distribution is given by the noise alone. This can be seen clearly in the PDMS pillars in Figure [ref], indicated by an arrow. While this might be thought to produce errors, other means of filtering background can be used that do not rely on the Z position, such as the mean image. It is more reliable to be unbiased when generating the zMod image since there is no certain way of determining whether a particular Z value should be assigned. If filtering must be done eventually, it can be done using other 3D data.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{505_false_variation}
 \caption{
 	False Z variation
 }
 \label{fig:falsezvariation}
\end{figure}

\section{zVar and zEdge}

The zEdge image is intended to improve the segmentation by bounding it.

Artificial edges can cut off parts of the cell that do not contain enough GFP.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{506_low_gfp}
 \caption{
 	Low GFP
 }
 \label{fig:lowgfp}
\end{figure}

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{507_bad_zedge}
 \caption{
 	Bad zEdge
 }
 \label{fig:badzedge}
\end{figure}

\section{Comparison with common methods}

Previous methods cannot account for the inconsistencies in the focus fluctuations and so are not really comparable in their quality. Below, some of the results from segmentation of images generated using several different method including the current method.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{508_segmentation_area_comparison}
 \caption{
 	Segmentation area comparison
 }
 \label{fig:areacomparison}
\end{figure}

[IMG 6 CELLS SAMPLED AT TIME INTERVALS SHOWING AREA FROM EACH METHOD]
[IMG RADIAL PLOTS OF 6 CELL INSTANCES SHOWING PROTRUSION ANGLES AND LENGTHS]
[IMG 6 CELLS -> 12 GRAPHS OF CELL PROTRUSION LENGTH AND ANGLE TIME SERIES]

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{509_protrusion_comparison}
 \caption{
 	Protrusion comparison
 }
 \label{fig:protrusioncomparison}
\end{figure}

\section{Errors and limitations}

Several possible errors that would affect segmentation results must be mentioned for completeness. Some of these error have not been observed, but are possible given certain conditions. Errors can be caused by faults in the microscope hardware, irregularities in the illumination of the environment for any reason, poor choices in imaging setup, or particular configurations of cells that cause the method to fail.

A controversial example of a possible error is a situation where two cells are superimposed in Z. In this case, a GFP profile for a single XY location could have two very prominent peaks. Currently, the method does not attempt to resolve this situation since it has not been observed in the current data, but trivially, it could be resolved by only taking account of the peak with the highest Z level, since the brightfield information is not 3D, and there is no way to recover any edge information about the lower cell if it is obscured. In this case, such a conflict could be noted and the GFP edge, which is not obscured, could act as a fallback for the segmentation. This information would allow the GFP edges, while they are suboptimal, to be incorporated into the outline of the rest of the cell if it is visible elsewhere in the brightfield. To reiterate, this situation has not been observed, but it is theoretically possible in such a 3D environment.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{510_hypothetical_superimposed_cells}
 \caption{
 	Superimposed cells
 }
 \label{fig:superimposedcells}
\end{figure}

In some cases, through a hardware fault or a temporary shift in the illumination of the environment, the level of the GFP intensity can drop in the whole experiment. This happened in one experiment done and caused the method to fail in a single frame, and subsequently rendered the area estimates in that frame for all objects unreliable.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{511_low_gfp_segmentation}
 \caption{
 	Low GFP segmentation
 }
 \label{fig:lowgfpsegmentation}
\end{figure}

If the illumination of the environment is not uniform, and regions at the top are significantly brighter than the bottom for example, when brightfield pixel values from different Z levels are brought together to generate zBF, it is possible that the intensities are so different as to be discontinuous, leading to the appearance of a false edge. This type of effect is shown in Figure [ref]. This can be alleviated partially by the choice of $R$ or $\Sigma$, since both control to a certain extent the smoothing between levels. If transitions between levels are smoother, artefacts such as these are less likely to form.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{512_cross_level_artefacts}
 \caption{
 	Cross-level artefacts
 }
 \label{fig:crosslevelartefacts}
\end{figure}

Finally, if the configuration of the microscope is chosen before imaging to yield generally low contrast brightfield images, edges may not be visible in any focal plane. In this case, the method of finding the in-focus representations of cells may not be very useful as no more information is revealed. In this case, an alternative might be use the segmentation of the GFP primarily and gather what results are available from the brightfield. As with hypothetical superimposed cells, edges from GFP and brightfield channels could be combined, but here it might be more effective to weight the edges found in GFP to be more reliable than those in the brightfield. This is subject for future work.

\begin{figure}[p]
 \centering
 \includegraphics[width=0.9\textwidth]{513_no_bf_contrast}
 \caption{
 	No BF contrast
 }
 \label{fig:nobfcontrast}
\end{figure}
