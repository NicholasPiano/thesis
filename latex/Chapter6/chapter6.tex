%*******************************************************************************
%****************************** Fourth Chapter *********************************
%*******************************************************************************

\chapter{Conclusion}

\ifpdf
    \graphicspath{{Chapter6/Figs/Raster/}{Chapter6/Figs/PDF/}{Chapter6/Figs/}}
\else
    \graphicspath{{Chapter6/Figs/Vector/}{Chapter6/Figs/}}
\fi

%********************************** %First Section  **************************************
\section{Summary}

Given the limitations on cell segmentation in 3D image data, the method described in this study performs well in overcoming problems and improves on the previously proposed method by Selinummi et al. by a large margin. It also compares favourably with previous attempts at segmentation using conventional means, such as Z projection of the GFP and segmentation at a constant Z level. It can also be used as a method to correct the autofocus fluctuations in brightfield data, which while not originally intended, is a natural consequence of the treatment of the 3D data.

The method depends on several parameters, such as R, the radius of the linear smoothing kernel; $\Delta Z$, the level correction of the edges; and $\Sigma$, the size of the gaussian smoothing in 3D. The method is mostly invariant under these parameters, but can be adjusted using $\Delta Z$ depending on the type of edges needed for segmentation. Ideally, these parameters would not have be chosen, they would simply be used to explore the data available. In this method, a lot of data is discarded, leaving the level-corrected images.

Throughout this study, the guiding philosophy has been that a cell segmentation method cannot be fully automatic, and must rely on human input as long as cells cannot be modelled as part of the segmentation. For now, the human brain is the most consistent pattern recognition available, but future methods could allow for more complex segmentation, such as matching mechanical models of cells to corresponding images and calculating the most likely routes for a cell to take. This philosophy has led to the creation of different images, such as zVar, which, while useful for segmentation, are most useful for observation and for letting a human know where to look for cells and allow for easier cell tracking.

\section{Further work}

This research leaves many opportunities for future study, such as improved cell segmentation and tracking, with and without human aid. This study has focussed only on the pre-processing of 3D image data to improve segmentation of cells in a 3D environment. Despite advances made, the process still does not use 3D information to help any segmentation algorithm. The segmentation is completely outsourced to systems like Cell Profiler and ImageJ. The current research also does not make any assumptions about sizes or shapes of cells, their features, or their behaviour or movements. Narrowing the search space by making assumptions or modelling the cells and their movements could result in more accurate segmentation. Below are some examples of expansion from this work.

\subsection{Enhanced microscope imaging with live cell tracking}

Throughout the current dataset, the images capture a wide area to encompass the movements of many cells and their interactions with the environment. This is done to make any measurements more relevant to the entire experiment, without focussing on one or two cells only. The problem with this approach is the large amount of empty space in the image that is processed due to lack of information about objects of interest. Each pixel of the image takes time to measure and process. Most parts of the image contain no objects and their imaging is not relevant to the experiment. Using this method of locating cell edges in 3D, a more accurate estimate of the portion of the image occupied by cells could be found and used to constrain the search space of the microscope. The field of view could be made to shift dynamically during the imaging period. This would result in shorter lengths of time between frames and the ability to zoom in on particular cells, raising the XY resolution available. This could be done by modifying microscope software to use this method on the fly.

\subsection{Pre-processing to segmentation}

The current method was designed to pre-process images to be passed to segmentation software. Instead of pre-processing the images, the information could be used to directly segment the images. There is no current segmentation method that investigates the vertical distribution of the brightfield data in 3D without compressing it, such as the Selinummi method. This is an open area of study and could be added to easily following on from the current research. This would also allow an analysis of shape parameters given a whole new dimension of data. Protrusion characteristics and finer details of cell movement could be recorded using this extra data. This would allow for more accurate cell tracking by adding to the information about cells as they change and move.

\subsection{Cell dynamic modelling}

During segmentation, assumptions are made about the size and shape of a cell and the properties of its surroundings in order to narrow the search space that must be analysed. These assumptions include types of edges and colour profiles inside cells; textures and known structures such as a nucleus or protrusions. The more specific the assumptions about a cell, the more constrained the search space becomes, but also the more biased any recogniser becomes. If assumptions are made with very little information, such as ``We are looking for cells with a radius of approximately 10 microns", the recognition will be biased towards circular structures with sizes around 10 microns, even structures which, upon further inspection, are not cells. Adding information allows better assumptions to be made. If the cells could be modelled using the information found in 3D using this method, the movements of each individual cell could be better understood allowing assumptions about their shape to be refined. Making assumptions about cells individually rather than all cells as a whole could lead to far more powerful segmentation.
